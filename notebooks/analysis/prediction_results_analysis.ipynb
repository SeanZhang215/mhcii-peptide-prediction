{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetMHCII Prediction Results Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides comprehensive analysis of NetMHCII prediction results, focusing on binding distributions and peptide characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from src.predictor.utils import SparkManager\n",
    "from src.analysis.visualization import (\n",
    "    BindingDistributionPlotter,\n",
    "    PlotConfig\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col, count, when, min as spark_min,\n",
    "    expr, length\n",
    ")\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkManager.create_spark_session(\"Prediction_Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all prediction results\n",
    "results_df = SparkManager.read_prediction_results(\n",
    "    spark,\n",
    "    \"/path/to/results/*_results.csv\"\n",
    ")\n",
    "\n",
    "# Cache the DataFrame for better performance\n",
    "results_df.cache()\n",
    "\n",
    "print(\"Total predictions:\", results_df.count())\n",
    "print(\"Unique samples:\", results_df.select(\"sample_id\").distinct().count())\n",
    "print(\"Memory usage:\", results_df.count() * len(results_df.columns) * 8 / 1e9, \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-transformation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for raw peptides without transformations\n",
    "raw_results = results_df.filter(\n",
    "    (col(\"inverted_manual\") == 0) & \n",
    "    (col(\"flipped\") == \"raw\")\n",
    ").cache()\n",
    "\n",
    "# Calculate statistics\n",
    "total_pairs = raw_results.count()\n",
    "stats = raw_results.agg(\n",
    "    (count(when(col(\"%Rank_EL\") > 5, True)) / total_pairs * 100)\n",
    "    .alias(\"above_5_percent\"),\n",
    "    (count(when(col(\"%Rank_EL\") <= 5, True)) / total_pairs * 100)\n",
    "    .alias(\"below_5_percent\"),\n",
    "    percentile_approx(\"%Rank_EL\", 0.5).alias(\"median_rank\")\n",
    ").collect()[0]\n",
    "\n",
    "print(\"\\nBinding Statistics:\")\n",
    "print(f\"Above 5%: {stats['above_5_percent']:.2f}%\")\n",
    "print(f\"Below 5%: {stats['below_5_percent']:.2f}%\")\n",
    "print(f\"Median Rank: {stats['median_rank']:.2f}\")\n",
    "\n",
    "# Sample data for plotting\n",
    "sample_size = 100000\n",
    "if total_pairs > sample_size:\n",
    "    plot_data = raw_results.select(\"%Rank_EL\").sample(False, sample_size/total_pairs).toPandas()\n",
    "else:\n",
    "    plot_data = raw_results.select(\"%Rank_EL\").toPandas()\n",
    "\n",
    "# Create plot\n",
    "plotter = BindingDistributionPlotter(PlotConfig(figsize=(12, 6)))\n",
    "fig = plotter.plot_rank_distribution(\n",
    "    plot_data,\n",
    "    title=\"Binding Rank Distribution (No Transformations)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation groups\n",
    "transformations = {\n",
    "    'No Transform': (col(\"inverted_manual\") == 0) & (col(\"flipped\") == \"raw\"),\n",
    "    'Inverted': (col(\"inverted_manual\") == 1) & (col(\"flipped\") == \"raw\"),\n",
    "    'Flipped': (col(\"inverted_manual\") == 0) & (col(\"flipped\") != \"raw\"),\n",
    "    'All Transform': (col(\"inverted_manual\") == 1) | (col(\"flipped\") != \"raw\")\n",
    "}\n",
    "\n",
    "# Analyze each transformation\n",
    "transform_stats = {}\n",
    "for name, condition in transformations.items():\n",
    "    df = results_df.filter(condition)\n",
    "    total = df.count()\n",
    "    \n",
    "    stats = df.agg(\n",
    "        (count(when(col(\"%Rank_EL\") > 5, True)) / total * 100)\n",
    "        .alias(\"above_5_percent\"),\n",
    "        (count(when(col(\"%Rank_EL\") <= 5, True)) / total * 100)\n",
    "        .alias(\"below_5_percent\"),\n",
    "        percentile_approx(\"%Rank_EL\", 0.5).alias(\"median_rank\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    transform_stats[name] = {\n",
    "        \"total\": total,\n",
    "        \"above_5\": stats[\"above_5_percent\"],\n",
    "        \"below_5\": stats[\"below_5_percent\"],\n",
    "        \"median\": stats[\"median_rank\"]\n",
    "    }\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "stats_df = pd.DataFrame(transform_stats).T\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add length column and analyze\n",
    "length_stats = (results_df\n",
    "    .withColumn(\"peptide_length\", length(col(\"Peptide\")))\n",
    "    .groupBy(\"peptide_length\")\n",
    "    .agg(\n",
    "        avg(\"%Rank_EL\").alias(\"mean_rank\"),\n",
    "        percentile_approx(\"%Rank_EL\", 0.5).alias(\"median_rank\"),\n",
    "        count(\"*\").alias(\"count\")\n",
    "    )\n",
    "    .orderBy(\"peptide_length\")\n",
    ").cache()\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "length_data = length_stats.toPandas()\n",
    "\n",
    "# Create plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Length distribution\n",
    "sns.barplot(data=length_data, x=\"peptide_length\", y=\"count\", ax=ax1)\n",
    "ax1.set_title(\"Peptide Length Distribution\")\n",
    "ax1.set_xlabel(\"Length\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "\n",
    "# Length vs Rank\n",
    "sns.lineplot(data=length_data, x=\"peptide_length\", y=\"median_rank\", ax=ax2)\n",
    "ax2.set_title(\"Peptide Length vs Binding Rank\")\n",
    "ax2.set_xlabel(\"Length\")\n",
    "ax2.set_ylabel(\"Median Rank EL\")\n",
    "ax2.set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-sample statistics\n",
    "sample_stats = (results_df\n",
    "    .groupBy(\"sample_id\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_peptides\"),\n",
    "        count(when(col(\"%Rank_EL\") < 2, True)).alias(\"strong_binders\"),\n",
    "        count(when((col(\"%Rank_EL\") >= 2) & (col(\"%Rank_EL\") < 10), True))\n",
    "        .alias(\"weak_binders\"),\n",
    "        percentile_approx(\"%Rank_EL\", 0.5).alias(\"median_rank\")\n",
    "    )\n",
    ").cache()\n",
    "\n",
    "# Add percentages\n",
    "sample_stats = (sample_stats\n",
    "    .withColumn(\"strong_binder_percent\", \n",
    "                col(\"strong_binders\") / col(\"total_peptides\") * 100)\n",
    "    .withColumn(\"weak_binder_percent\", \n",
    "                col(\"weak_binders\") / col(\"total_peptides\") * 100)\n",
    ")\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "stats_pd = sample_stats.toPandas()\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Binder percentages\n",
    "stats_pd.plot(\n",
    "    kind='bar',\n",
    "    x='sample_id',\n",
    "    y=['strong_binder_percent', 'weak_binder_percent'],\n",
    "    stacked=True,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Binder Distribution by Sample\")\n",
    "axes[0].set_xlabel(\"Sample\")\n",
    "axes[0].set_ylabel(\"Percentage\")\n",
    "\n",
    "# Median ranks\n",
    "stats_pd.plot(\n",
    "    kind='bar',\n",
    "    x='sample_id',\n",
    "    y='median_rank',\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Median Rank by Sample\")\n",
    "axes[1].set_xlabel(\"Sample\")\n",
    "axes[1].set_ylabel(\"Median Rank EL\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding Motif Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze core sequences\n",
    "core_stats = (results_df\n",
    "    .filter(col(\"%Rank_EL\") <= 2)  # Focus on strong binders\n",
    "    .groupBy(\"Core\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"frequency\"),\n",
    "        avg(\"%Rank_EL\").alias(\"mean_rank\"),\n",
    "        collect_set(\"sample_id\").alias(\"samples\")\n",
    "    )\n",
    "    .withColumn(\"num_samples\", size(col(\"samples\")))\n",
    "    .orderBy(col(\"frequency\").desc())\n",
    ").cache()\n",
    "\n",
    "# Show top cores\n",
    "print(\"Most frequent core sequences in strong binders:\")\n",
    "display(core_stats.limit(20).toPandas())\n",
    "\n",
    "# Core length distribution\n",
    "core_length_dist = (core_stats\n",
    "    .withColumn(\"core_length\", length(col(\"Core\")))\n",
    "    .groupBy(\"core_length\")\n",
    "    .agg(count(\"*\").alias(\"count\"))\n",
    "    .orderBy(\"core_length\")\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=core_length_dist, x=\"core_length\", y=\"count\")\n",
    "plt.title(\"Core Sequence Length Distribution\")\n",
    "plt.xlabel(\"Core Length\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save statistics to files\n",
    "SparkManager.save_prediction_results(\n",
    "    sample_stats,\n",
    "    \"analysis_results/sample_statistics.csv\"\n",
    ")\n",
    "\n",
    "SparkManager.save_prediction_results(\n",
    "    core_stats,\n",
    "    \"analysis_results/core_statistics.csv\"\n",
    ")\n",
    "\n",
    "# Clean up\n",
    "results_df.unpersist()\n",
    "raw_results.unpersist()\n",
    "sample_stats.unpersist()\n",
    "core_stats.unpersist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
